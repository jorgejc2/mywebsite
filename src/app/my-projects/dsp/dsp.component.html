<div class="project-header">
    <h1 class="hover-title">Digital Signal Processing</h1>
    <img src="../../assets/ece391_maze.jpg" alt="ECE391 Maze Demo" style="width: 100%; height: 350px;">
</div>
<div class="project">
    <div class="table-contents">
        <div class="go-back">
            <svg xmlns="http://www.w3.org/2000/svg"
            width="9.72222in" height="9.72222in"
            viewBox="0 0 875 875">
            <path id="Selection"
                fill="none" stroke="white" stroke-width="1"
                d="M 255.00,277.00
                C 255.00,277.00 286.00,308.00 286.00,308.00
                    286.00,308.00 304.00,326.00 304.00,326.00
                    307.91,329.91 319.58,340.60 321.26,345.00
                    323.91,351.93 320.83,359.77 313.00,360.77
                    303.98,361.93 293.96,348.96 288.00,343.00
                    288.00,343.00 235.00,290.00 235.00,290.00
                    228.83,283.83 217.03,275.17 217.03,266.00
                    217.03,263.86 217.20,261.94 218.17,260.00
                    220.05,256.26 232.29,244.71 236.00,241.00
                    236.00,241.00 284.00,193.00 284.00,193.00
                    288.76,188.24 301.70,174.15 307.00,172.01
                    316.03,168.36 325.04,175.55 322.19,185.00
                    320.36,191.10 308.84,201.16 304.00,206.00
                    304.00,206.00 286.00,224.00 286.00,224.00
                    286.00,224.00 255.00,255.00 255.00,255.00
                    255.00,255.00 469.00,255.00 469.00,255.00
                    488.33,255.00 524.56,253.90 542.00,256.43
                    564.56,259.70 585.68,268.66 604.00,282.16
                    675.73,334.98 676.17,444.52 607.00,499.55
                    595.65,508.58 581.74,516.32 568.00,521.00
                    555.44,525.27 540.29,528.84 527.00,529.00
                    475.81,529.60 427.34,506.18 402.31,460.00
                    390.54,438.29 384.87,418.73 385.00,394.00
                    385.04,386.21 387.82,380.05 397.00,381.23
                    403.94,382.11 405.89,386.81 406.71,393.00
                    406.71,393.00 407.29,405.00 407.29,405.00
                    408.84,417.66 413.39,432.72 419.32,444.00
                    440.08,483.47 480.59,507.52 525.00,507.00
                    538.20,506.84 557.17,502.06 569.00,496.24
                    585.27,488.25 598.95,478.13 610.54,464.00
                    654.28,410.65 640.39,332.70 583.00,295.34
                    566.27,284.45 543.03,277.03 523.00,277.00
                    523.00,277.00 504.00,277.00 504.00,277.00
                    504.00,277.00 467.00,277.00 467.00,277.00
                    467.00,277.00 255.00,277.00 255.00,277.00 Z" fill="#fff"/>
            </svg>
            <p (click)="goProjects()">go back</p>
        </div>
        <div class="contents">
            <p>Contents</p>
            <ul>
                <li (click)="goIntro(introduction)"><a>Introduction</a></li>
                <li (click)="goIntro(summer_project)"><a>My Summer Project</a></li>
                <li (click)="goIntro(resources)"><a>Resources</a></li>
            </ul>
        </div>
    </div>
    <div class="main-content">
        <p id="introduction" #introduction>
            <strong><u>Introduction</u></strong>
        </p>
        <p>
            <strong>Digital Signal Processing was a topic I believed I would never figure out.</strong> That mentality completely changed after interning with Motorola Solutions the summer of 2022. When I had applied for the internship, it was for a role in embedded systems, but as the start date of the internship approached, my manager gave me more details on the project I was going to work on. It was definitely embedded systems, but little did I know that I would be working with a software defined radio.
        </p>
        <p>
            In this article, I'd like to share a bit about my summer internship experience as well as details about the project I worked on. Of all the classes I've taken at UIUC, I felt as if the ones covering digital signal processing went over my head. That's why when I found out that I would be working with an SDR, I was scared but also excited knowing that I would have 12 full weeks to strengthen my understanding of a field that I didn't fully understand and apply it to my project. Hopefully this article motivates others to give digital signal processing a chance and/or give ideas on how to tackle digital signal processing projects where device memory is a big concern.
        </p>
        <p id="summer_project" #summer_project>
            <strong><u>My Summer Project</u></strong>
        </p>
        <p>
            The project I was tasked with was creating a multi-threaded script in Python that would allow this software defined radio to listen for radio frequency activity for prolonged periods of time and classify different signals. Attributes were marked down for each class of signal including the center frequency it was found, the timestamps the signal was found, its bandwidth, amplitude, and the number of times the signal appeared on and off. This data is saved, and a separate script is used to predict when and what signal it should transmit from the radio. 
        </p>
        <p>
            At a more general scope, the goal of the script was to utilize the radio’s capabilities to process these signals online and predict frequent radio patterns that could be used for recreating the activity that it recorded. This project was geared towards a market who require a radio with many enhanced features including the ability to mask signal activity. The issue with radio frequency activity is that radio frequencies are everywhere and essential for communication, but with the right equipment, are extremely visible. There are a variety of standards that transmit radio frequencies including LTE, Bluetooth, TDMR, and Wi-Fi. It’s difficult to mask the signal activity you may use for communication. Thus, this project takes the alternative approach of using deception to replicate artificial signal activity to misguide an adversarial who may be analyzing this activity. 
        </p>
        <p>
            To transmit signals from the SDR, a .WAV audio file must be loaded onto the device or even just a file with raw IQ sample data. If you are not familiar with IQ samples, they are simply a manner of representing signal activity by using one antenna to pick up samples that make up the real component of a sample, and a second antenna that is one quadrature out of phase to create the imaginary component of that sample. More information on IQ samples can be found <a href="https://www.tek.com/en/blog/quadrature-iq-signals-explained#:~:text=Quadrature%20signals%2C%20also%20called%20IQ,as%20in%20complex%20signal%20analysis.">here</a>. Though uploading such files may be straightforward, to improve the user experience and simulate realistic activity, that’s where this script comes into play. There is a physical switch on the device which alternates between recording and transmission on the radio. The radio can simply be trained by leaving it in recording mode for a prolonged period. During this time, the radio can be trained in lab or in a real-life scenario. Once it is desired for the radio to act as a decoy and conduct deception by replicating real-like signal activity, the flip is switched, and the radio can begin its transmission immediately. 
        </p>
        <p>
            <strong>Though the goal of my project was straightforward, I didn't know where to begin.</strong> Prior to the internship, I had taken a course in digital signal processing (ECE 310 at UIUC), but I was not confident with my knowledge. Luckily, I had taken a complimentary laboratory course that focused on the applications of digital signal processing (ECE 311) and with exposure and resources at my fingertips, I made sure to review and research as much as possible during the beginning of my internship. As I studied and discussed with my coworkers, my confidence grew, and I quickly devised a structure on how to accomplish this project goal they had set for me. 
        </p>
        <p>
            As I settled into the cubicle that I would be working out of for the majority of the summer, I began experimenting with an <a href="https://www.analog.com/en/design-center/evaluation-hardware-and-software/evaluation-boards-kits/ADALM-PLUTO.html#eb-overview">ADALM-PLUTO SDR Learning Module</a> which the team had plenty of. These allowed us to test and simulate our codebase before uploading them onto the SDR prototype. I wrote various Jupyter Notebooks to test and visualize my ideas, and this further solidified my knowledge and allowed me to find direction with the project. For anyone who wishes to dive further into digital signal processing and have the ability to acquire an ADALM-PLUTO, I highly recommend checking out <a href="https://pysdr.org/index.html">this website resource</a> which ended up being another vital resource for me. 
        </p>
        <p>
            When it came to work with the SDR, I quickly investigated potential hardware limitations. At this point in my undergraduate career, I had become very familiar with digital signal processing concepts, but not so much with implementation from scratch. Therefore, I chose to curate a Python script so that I could use the various libraries at my disposal including NumPy and SciPy for data and signal processing. The schema that I devised involved using the multi-threaded library offered in Python so that I could allow the radio to periodically collect IQ samples and then process them. One of the greatest limitations of this library is that it does not make use of the physical threads offered on CPU. Underneath, it merely schedules Python functions on a single thread. The benefit of concurrency should hopefully be transparent here as with C, we can utilize the POSIX standard library of threads to create concurrent functions where one periodically acquires IQ samples, and the other processes them. To achieve the same level of efficiency with this Python script, I sacrificed memory.  
        </p>
        <p>
            My very first implementation relied on a main thread to periodically acquire samples and publish them to a new file on each call. The second thread would open each file and process them one by one. This approach was most definitely efficient as the main thread was able to periodically capture data without fail but was most definitely data heavy. One requirement was that the SDR be configured to look at a bandwidth spectrum of 40 MHz. Per Nyquist Theorem, this would mean that the sampling rate should be twice this. This is so that we capture enough samples to accurately reconstruct signals in this range. Fortunately, with capturing IQ samples on the device, it already contained two antennas which meant every time it was recording a sample, it was publishing two samples (one from each antenna). This meant the SDR could hold a sampling rate of 40 MHz instead of 80 MHz without violating Nyquist. Though the sampling rate is halved, this does not mean we are necessarily saving memory. Notice that a radio with a single antenna would need a sampling rate of 80 MHz, but this SDR with two antennas has a sampling rate of 40 MHz because it is publishing TWICE as much data. Thus, the radio is recording 2*40 Mega samples per second. This is where I realized I needed another approach that was efficient and memory effective. 
        </p>
        <p>
            <strong>Welch's Method is a digital signal processing technique used to approximate signals,</strong> and it was exactly what was needed. At a high level, it's very simple in that it replicates signal activity without returning as many samples. The number of samples the method returns is configurable among other things. Thanks to the abundant number of libraries available in Python, especially with signal processing, it was easy to incorporate this method into my scripts, and the results I found right away were astounding. To give more detail about how these samples are used to analyze signals, it’s important to know the difference between analyzing signals in the time and frequency domain. The time domain is something everyone has witness naturally. An example of a graph in the time domain would be if we wanted to look at the distance a car covers over a period. The x-axis could be minutes, and the y-axis could be the number of miles. But for signals, the graph becomes nearly meaningless to the human eye. The x-axis is still in time, and the y-axis is the amplitude of the signal. Yet, it takes much more effort to gauge the center frequency of a signal from the time-domain than the frequency-domain. Through a method called the Fast Fourier Transform method though, we could transform this signal graph from the time to the frequency domain. In the frequency domain, things become much clearer. I coded a quick example to display the results of a signal in its time domain versus its frequency domain. The bulk of the code is from pysdr.org, I just added an additional graph that shows the signal in the time domain.
        </p>
        <img src="../../../assets/time_to_frequency.png" alt="Example of signal from time to frequency domain">
        <!-- <iframe frameborder="0" width="100%" height="500px" src="https://replit.com/@JorgeChavez14/BasicSignalNoiseAndGraphing?lite=true"></iframe> -->
        <p>
            <i class="caption">Since matplotlib generates visual graphs, results may load slowly so I recommend running the code in your local IDE and viewing the results</i>
        </p>
        <p>
            As you can see above, the signal in the time domain looks quite messy. It's a simple sin wave oscillating at a frequency rate of 50 Hz with noise surrounding the signal. To the human eye, it’s impossible to look at this graph, discern the sin wave, and count how many times it oscillates in one second to determine its frequency. After transforming the signal to the frequency domain though using the Fast Fourier Transform method, it becomes much clearer. The sin wave can be seen at 50 Hz on the x-axis where its amplitude is much greater than everything else surrounding it. An indication of how much of that frequency was present during the amount of time we captured the signal. Everything else in this frequency domain graph can be considered noise. Typically, the threshold where noise congregates is called the noise floor.
        </p>
    <pre class="prettyprint lang-python linenums:1">    import numpy as np
    import matplotlib.pyplot as plt
    from scipy import signal
    
    Fs = 300 # sample rate
    Ts = 1/Fs # sample period
    N = 1048576 # number of samples to simulate
    psd_length = 256
    
    t = Ts*np.arange(N)
    x = np.exp(1j*2*np.pi*50*t) # simulate sinusoid at 50 Hz
    
    n = (np.random.randn(N) + 1j*np.random.randn(N))/np.sqrt(2) # complex noise with unity power
    noise_power = 2
    r = x + n * np.sqrt(noise_power)
    
    PSD = (np.abs(np.fft.fft(r))/N)**2
    PSD_log = 10.0*np.log10(PSD)
    PSD_shifted = np.fft.fftshift(PSD_log)
    f = np.arange(Fs/-2.0, Fs/2.0, Fs/N) # start, stop, step
    
    _, psd = signal.welch(r, Fs, 'hamming', psd_length, return_onesided=True, scaling='density', average='median')
    psd_dB = np.fft.fftshift(10*np.log10((np.abs(psd)/psd.shape[0])**2)) + 44  # small miscalculation I made requiring an offset to correct the graph
    f_welch = np.linspace(Fs/-2.0, Fs/2.0, psd_length)
    
    plt.figure(figsize=(18,12))
    plt.subplot(121)
    plt.plot(t, np.sin(2*np.pi*50*t))
    plt.xlabel("Time [s]")
    plt.ylabel("Amplitude")
    plt.title("Time Domain")
    plt.subplot(122)
    plt.plot(f, PSD_shifted, label="FFT")
    plt.plot(f_welch, psd_dB, label="Welch")
    plt.xlabel("Frequency [Hz]")
    plt.ylabel("Magnitude [dB]")
    plt.title("Frequency Domain")
    plt.grid(True)
    plt.legend()
    plt.show()
    </pre>
    <p>
        <i class="caption">Note that the samples used are above 1 million yet Welch only outputs 256 samples</i>
    </p>
    <p>
        Here, I've added more modifications where I still transform the signal to the frequency domain using a standard FFT, but I also transform it using Welch's method. Pay close attention to the variable labeled <strong>'psd_length'</strong>. This variable is used to set the output size of Welch's method. This number can be anything less than or equal to the number of samples fed to the Welch function, but the smaller the number, the worse the precision. You would imagine that specifying an output of 256 samples would lead to such a gross approximation of the signal, yet the results below are interesting.
    </p>
    <img src="../../../assets/welch_vs_fft.png" alt="Welch vs FFT Graph">
    <p>
        <i class="caption">Welch's Method displays a very good approximation while using much less memory</i>
    </p>
    <p>
        With this drastic improvement in memory, I knew I took a step in the right direction. There are of course tradeoffs with this method which involves the loss of precision. This loss of precision was nothing too drastic. The bandwidth and amplitude could still be determined to a reasonable degree. The only disadvantage this introduced was being able to determine the modulation type of a signal. At an extremely high level, modulation is how a signal is encoded so that a receiver on the other end can decode the signal and interpret the information sent if they are aware of the modulation type used. As nice as this would have been to determine, it was out of my scope for the summer and would have most definitely required more memory usage.
    </p>
    <p>
        By approximating signals, I was able to fit minutes’ worth of IQ samples in memory before processing and flushing them to a file. And while my script was highly configurable, I chose to only hold 50 seconds of data at once. After 50 seconds were recorded, I converted the samples to the frequency domain. The only samples I considered relevant were those above a base threshold that was set in decibels. If samples were above this threshold, then I would keep them, otherwise I would discard them since I assumed they were samples representing the noise floor. This base threshold was set closely above the noise floor used to save storage memory because the objective was to identify and characterize signals, not random noise. On top of saving the samples I considered relevant, I also saved the indices of where those samples were in the buffer. Once I had my samples of relevant data and their indices, they were saved as binary files, and the array of samples could then be discarded so that then next set of samples could be collected for the subsequent 50 seconds.
    </p>
    <p>
        To make it possible to recreate the activity that was recorded, at the end of the script, I would save a text file that held the configurations of the device when the script first ran. On every run of this Python script, a lot of parameters were configurable such as the frequencies to look at, the sample rate and amount of bandwidth to analyze. Also, how precise Welch's method should approximate signals, and how much time this script should run for. Once the script began running, those parameters were then saved to a text file. By knowing the setup of the SDR, I was able to rebuild the buffer that was used to hold the samples and map the indices of the buffer to a frequency and time (this buffer was two dimensional where the x indices were frequencies in MHz, and the y indices were seconds in 100 MS intervals). I could then load one IQ data file and their indices files from the device storage and map them to this buffer. Every sample that wasn't mapped into the buffer was assumed to be the noise floor since those were the only samples that were never saved. Once I recreated this one buffer, I would seek out every signal in this buffer and start describing them. After analyzing one buffer worth of data, I then reset the buffer, and loaded a new set of IQ data and index files. This would process repeated until every set had been analyzed.
    </p>
    <p>
        The amount of memory being saved was incredible. There is a notebook in my <strong>PlutoSDR</strong> Github page that is called <i>iq_collection.ipynb</i> which explains my process thoroughly in code. This notebook can be used to collect samples using an ADALM Pluto SDR Learning Device, but if you do not have one on hand, there is also a portion of code that generates fake signal activity in place of live IQ data. With the standard configuration I set up with the fake signal generator, the IQ sample data using an FFT used up 2,048,000 bytes, or 2 MB. In comparison, the signal saved as binary data using the method I described above as well as a text file describing the configurations of the fake signal only used 30,219 bytes. That's only 0.03 MB. This may seem minuscule, but once again, keep in mind that this was only for a duration of 50 seconds, but this number can quickly spike over the course of hours.
    </p>
    <img src="../../../assets/iq_collection_memory_usage.png" alt="Memory usage results from standard FFT and Welch">
    <p>
        <i class="caption">Memory usage results</i>
    </p>
    <p>
        If you wish to play around with the fake signal generator or want to use your own Pluto SDR alongside the script, there are instructions on how to do so in the 
        notebook as well. 
    </p>
    <p id="resources" #resources>
        <strong><u>Useful Resources</u></strong>
    </p>
    <p>
        Throughout this article I've explained and linked some resources throughout that helped me a lot during my project, but I'd like to describe them in more detail for 
        any wanting to get into digital signal processing or need clarification on some concepts.
    </p>


    </div>
    <div class="right-space">
    </div>
</div>
<!-- <div class="toFooter"></div> -->
